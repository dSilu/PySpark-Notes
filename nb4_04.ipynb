{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user = \"etl_user\",\n",
    "    password = \"****\"\n",
    ")\n",
    "\n",
    "my_cur = mydb.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cur.execute(\n",
    "    \"CREATE DATABASE IF NOT EXISTS pysparkdb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user = \"etl_user\",\n",
    "    password = \"****\",\n",
    "    database = \"pysparkdb\"\n",
    ")\n",
    "\n",
    "my_cur = mydb.cursor()\n",
    "\n",
    "my_cur.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS student(\n",
    "        studentID VARCHAR(50) NOT NULL,\n",
    "        name VARCHAR(50) NOT NULL,\n",
    "        gender VARCHAR(50) NOT NULL\n",
    "    )\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('student',)\n"
     ]
    }
   ],
   "source": [
    "my_cur.execute(\"SHOW TABLES\")\n",
    "\n",
    "for x in my_cur:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert records\n",
    "sql = \"INSERT INTO student (studentID, name, gender) VALUES (%s, %s, %s)\"\n",
    "val = [ \n",
    "    (\"si1\", \"Robin\", \"M\"),\n",
    "    (\"si2\", \"Maria\", \"F\"),\n",
    "    (\"si3\", \"Julie\", \"F\"),\n",
    "    (\"si4\", \"Bob\", \"M\"),\n",
    "    (\"si6\", \"William\", \"M\")\n",
    "]\n",
    "\n",
    "my_cur.executemany(sql,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cur.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fedora:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>JOIN-App</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff654f04e20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"JOIN-App\").getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26064/1826124330.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, con=mydb)\n",
      "/run/media/ashrulochan/Sector8/Books-and-Notes/To_be_continued/PySparkRecipes/spark_ttl_env/lib64/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/run/media/ashrulochan/Sector8/Books-and-Notes/To_be_continued/PySparkRecipes/spark_ttl_env/lib64/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+------+\n",
      "|studentID|   name|gender|\n",
      "+---------+-------+------+\n",
      "|      si1|  Robin|     M|\n",
      "|      si2|  Maria|     F|\n",
      "|      si3|  Julie|     F|\n",
      "|      si4|    Bob|     M|\n",
      "|      si6|William|     M|\n",
      "+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cursor = mydb.cursor()\n",
    "query = \"SELECT * FROM student\"\n",
    "pdf = pd.read_sql(query, con=mydb)\n",
    "cursor.close()\n",
    "\n",
    "df = spark.createDataFrame(pdf)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+------------+\n",
      "|trim(studentID)|trim(name)|trim(gender)|\n",
      "+---------------+----------+------------+\n",
      "|            si1|     Robin|           M|\n",
      "|            si2|     Maria|           F|\n",
      "|            si3|     Julie|           F|\n",
      "|            si4|       Bob|           M|\n",
      "|            si6|   William|           M|\n",
      "+---------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if any unnecessary space or symbols are there use trim to clean data\n",
    "student_df = df.select(trim(df.studentID), trim(df.name), trim(df.gender))\n",
    "student_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+------+\n",
      "|studentID|   Name|Gender|\n",
      "+---------+-------+------+\n",
      "|      si1|  Robin|     M|\n",
      "|      si2|  Maria|     F|\n",
      "|      si3|  Julie|     F|\n",
      "|      si4|    Bob|     M|\n",
      "|      si6|William|     M|\n",
      "+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename column names\n",
    "student_df = student_df.withColumnRenamed('trim(studentID)', 'studentID')\\\n",
    "    .withColumnRenamed('trim(name)', 'Name').withColumnRenamed('trim(gender)', 'Gender')\n",
    "\n",
    "student_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- studentID: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {\n",
    "    \"studentID\": [\"si1\", \"si3\", \"si1\", \"si2\", \"si3\", \"si4\", \"si5\", \"si4\", \"si2\"],\n",
    "    \"subject\": [\"Python\", \"Java\", \"Java\", \"Python\", \"Ruby\", \"C++\", \"C\", \"Python\", \"Java\"]\n",
    "}\n",
    "\n",
    "sub_df = pd.DataFrame(json_data)\n",
    "sub_df.to_json(\"subject.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/ashrulochan/Sector8/Books-and-Notes/To_be_continued/PySparkRecipes/spark_ttl_env/lib64/python3.10/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sql_context = SQLContext(spark.sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/ashrulochan/Sector8/Books-and-Notes/To_be_continued/PySparkRecipes/spark_ttl_env/lib64/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/run/media/ashrulochan/Sector8/Books-and-Notes/To_be_continued/PySparkRecipes/spark_ttl_env/lib64/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|studentID|subject|\n",
      "+---------+-------+\n",
      "|      si1| Python|\n",
      "|      si3|   Java|\n",
      "|      si1|   Java|\n",
      "|      si2| Python|\n",
      "|      si3|   Ruby|\n",
      "|      si4|    C++|\n",
      "|      si5|      C|\n",
      "|      si4| Python|\n",
      "|      si2|   Java|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# subject_df = sql_context.read.format(\"json\").load(\"subject.json\")\n",
    "# subject_df.show()\n",
    "\n",
    "df = pd.read_json(\"subject.json\")\n",
    "subject_df = spark.createDataFrame(df)\n",
    "subject_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- studentID: string (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+-----+------+\n",
      "|studentID|subject|studentID| Name|Gender|\n",
      "+---------+-------+---------+-----+------+\n",
      "|      si1| Python|      si1|Robin|     M|\n",
      "|      si1|   Java|      si1|Robin|     M|\n",
      "|      si2| Python|      si2|Maria|     F|\n",
      "|      si2|   Java|      si2|Maria|     F|\n",
      "|      si3|   Java|      si3|Julie|     F|\n",
      "|      si3|   Ruby|      si3|Julie|     F|\n",
      "|      si4|    C++|      si4|  Bob|     M|\n",
      "|      si4| Python|      si4|  Bob|     M|\n",
      "+---------+-------+---------+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# inner join\n",
    "joined_df = subject_df.join(student_df, subject_df.studentID==student_df.studentID, how='inner')\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+------+\n",
      "|studentID|subject| Name|Gender|\n",
      "+---------+-------+-----+------+\n",
      "|      si1| Python|Robin|     M|\n",
      "|      si1|   Java|Robin|     M|\n",
      "|      si2| Python|Maria|     F|\n",
      "|      si2|   Java|Maria|     F|\n",
      "|      si3|   Java|Julie|     F|\n",
      "|      si3|   Ruby|Julie|     F|\n",
      "|      si4|    C++|  Bob|     M|\n",
      "|      si4| Python|  Bob|     M|\n",
      "+---------+-------+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# or\n",
    "joined_df = subject_df.join(student_df, on='studentID', how='inner')\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save inner joined data to json\n",
    "\n",
    "joined_df.write.format('json').save('inner_joined_tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+------+\n",
      "|studentID|subject| Name|Gender|\n",
      "+---------+-------+-----+------+\n",
      "|      si3|   Java|Julie|     F|\n",
      "|      si1| Python|Robin|     M|\n",
      "|      si2| Python|Maria|     F|\n",
      "|      si1|   Java|Robin|     M|\n",
      "|      si4|    C++|  Bob|     M|\n",
      "|      si3|   Ruby|Julie|     F|\n",
      "|      si5|      C| null|  null|\n",
      "|      si2|   Java|Maria|     F|\n",
      "|      si4| Python|  Bob|     M|\n",
      "+---------+-------+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# left outer join\n",
    "left_outer_joined_df = subject_df.join(student_df, on = 'studentID', how='left_outer')\n",
    "left_outer_joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+------+\n",
      "|studentID|subject|   Name|Gender|\n",
      "+---------+-------+-------+------+\n",
      "|      si1|   Java|  Robin|     M|\n",
      "|      si1| Python|  Robin|     M|\n",
      "|      si2|   Java|  Maria|     F|\n",
      "|      si2| Python|  Maria|     F|\n",
      "|      si3|   Ruby|  Julie|     F|\n",
      "|      si3|   Java|  Julie|     F|\n",
      "|      si4| Python|    Bob|     M|\n",
      "|      si4|    C++|    Bob|     M|\n",
      "|      si6|   null|William|     M|\n",
      "+---------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# right outer join\n",
    "right_outer_join_df = subject_df.join(student_df, on='studentID', how='right_outer')\n",
    "right_outer_join_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+------+\n",
      "|studentID|subject|   Name|Gender|\n",
      "+---------+-------+-------+------+\n",
      "|      si1| Python|  Robin|     M|\n",
      "|      si1|   Java|  Robin|     M|\n",
      "|      si2| Python|  Maria|     F|\n",
      "|      si2|   Java|  Maria|     F|\n",
      "|      si3|   Java|  Julie|     F|\n",
      "|      si3|   Ruby|  Julie|     F|\n",
      "|      si4|    C++|    Bob|     M|\n",
      "|      si4| Python|    Bob|     M|\n",
      "|      si5|      C|   null|  null|\n",
      "|      si6|   null|William|     M|\n",
      "+---------+-------+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# full outer join\n",
    "full_outer_joined = subject_df.join(student_df, on='studentID', how='outer')\n",
    "full_outer_joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_ttl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e5fe3c56a0f8f95c221320b0bd7b50af4bf76cfb19c727317c7f47c8ed217d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
