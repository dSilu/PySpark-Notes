{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fedora:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Page-2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbee5fe0730>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Page-2\").getOrCreate()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'd', 'm', 't', 'e', 'u']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"b d m t e u\".split()\n",
    "\n",
    "rdd1 = spark.sparkContext.parallelize(l, 2)\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vowelCheckFunction(x: str) -> int:\n",
    "    \"\"\"takes a letter and checks if it is consonant or vowel\"\"\"\n",
    "\n",
    "    if x in [\"a\", \"e\", \"i\", \"o\", \"u\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "vowelCheckFunction(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('b', 0), ('d', 0), ('m', 0), ('t', 0), ('e', 1), ('u', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a paired RDD\n",
    "rdd2 = rdd1.map(lambda x: (x, vowelCheckFunction(x)))\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'd', 'm', 't', 'e', 'u']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys \n",
    "rdd2.keys().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values\n",
    "rdd2.values().collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aggregation Operations**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['filamentA', '100W', 605],\n",
       " ['filamentB', '100W', 683],\n",
       " ['filamentB', '100W', 691]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "filament_data = [ \n",
    "    [\"filamentA\", '100W', 605], # filament type, bulb power, life in hours\n",
    "    [\"filamentB\", '100W', 683],\n",
    "    [\"filamentB\", '100W', 691],\n",
    "    [\"filamentB\", '200W', 561],\n",
    "    [\"filamentA\", '200W', 530],\n",
    "    [\"filamentA\", '100W', 619],\n",
    "    ['filamentB', '100W', 686],\n",
    "    ['filamentB', '200W', 600],\n",
    "    ['filamentB', '100W', 696],\n",
    "    ['filamentA', '200W', 579],\n",
    "    ['filamentA', '200W', 520],\n",
    "    ['filamentA', '100W', 622],\n",
    "    ['filamentA', '100W', 668],\n",
    "    ['filamentB', '200W', 569],\n",
    "    ['filamentB', '200W', 555],\n",
    "    ['filamentA', '200W', 541]\n",
    "]\n",
    "\n",
    "fil_rdd = spark.sparkContext.parallelize(filament_data)\n",
    "\n",
    "fil_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', 605),\n",
       " ('filamentB', 683),\n",
       " ('filamentB', 691),\n",
       " ('filamentB', 561)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a paired RDD from fil_rdd\n",
    "fil_paired_rdd1 = fil_rdd.map(lambda x: (x[0], x[2])) # filament type, life in hours\n",
    "fil_paired_rdd1.take(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Mean life based on filament type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentA', [605, 1]),\n",
       " ('filamentB', [683, 1]),\n",
       " ('filamentB', [691, 1]),\n",
       " ('filamentB', [561, 1]),\n",
       " ('filamentA', [530, 1])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean life time based on filament type\n",
    "# add an extra column with 1\n",
    "fil_paired_rdd1_1 = fil_paired_rdd1.map(lambda x: (x[0], [x[1], 1]))\n",
    "fil_paired_rdd1_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filamentB', [5041, 8]), ('filamentA', [4684, 8])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count\n",
    "fil_paired_rdd1_1_sum_count = fil_paired_rdd1_1.reduceByKey(lambda x1, x2 : [x1[0] + x2[0], x1[1] + x2[1]])\n",
    "fil_paired_rdd1_1_sum_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['filamentB', 630.125, 8], ['filamentA', 585.5, 8]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find mean\n",
    "\n",
    "fil_paired_rdd_1_mean_count = fil_paired_rdd1_1_sum_count.map(lambda x: [x[0], float(x[1][0])/x[1][1], x[1][1]])\n",
    "fil_paired_rdd_1_mean_count.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Mean life based on bulb power**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100W', [605, 1]),\n",
       " ('100W', [683, 1]),\n",
       " ('100W', [691, 1]),\n",
       " ('200W', [561, 1]),\n",
       " ('200W', [530, 1])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_paired_rdd2 = fil_rdd.map(lambda x: (x[1], x[2])) # choose bulb power and life in hour\n",
    "fil_paired_rdd2_1 = fil_paired_rdd2.map(lambda x: (x[0], [x[1], 1]))\n",
    "fil_paired_rdd2_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100W', [5270, 8]), ('200W', [4455, 8])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_paired_rdd2_1_sum_count = fil_paired_rdd2_1.reduceByKey(lambda x1, x2 : [x1[0]+x2[0], x1[1]+x2[1]])\n",
    "fil_paired_rdd2_1_sum_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['100W', 658.75], ['200W', 556.875]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean\n",
    "fil_paired_rdd2_1_mean_count = fil_paired_rdd2_1_sum_count.map(lambda val : [val[0], float(val[1][0]/val[1][1])])\n",
    "fil_paired_rdd2_1_mean_count.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Mean life time based on filament type as well as bulb power**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['filamentA', '100W', 605],\n",
       " ['filamentB', '100W', 683],\n",
       " ['filamentB', '100W', 691],\n",
       " ['filamentB', '200W', 561]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_rdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('filamentA', '100W'), [605, 1]],\n",
       " [('filamentB', '100W'), [683, 1]],\n",
       " [('filamentB', '100W'), [691, 1]],\n",
       " [('filamentB', '200W'), [561, 1]],\n",
       " [('filamentA', '200W'), [530, 1]],\n",
       " [('filamentA', '100W'), [619, 1]],\n",
       " [('filamentB', '100W'), [686, 1]],\n",
       " [('filamentB', '200W'), [600, 1]],\n",
       " [('filamentB', '100W'), [696, 1]],\n",
       " [('filamentA', '200W'), [579, 1]],\n",
       " [('filamentA', '200W'), [520, 1]],\n",
       " [('filamentA', '100W'), [622, 1]],\n",
       " [('filamentA', '100W'), [668, 1]],\n",
       " [('filamentB', '200W'), [569, 1]],\n",
       " [('filamentB', '200W'), [555, 1]],\n",
       " [('filamentA', '200W'), [541, 1]]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_rdd_2 = fil_rdd.map(lambda val: [(val[0], val[1]), [val[2], 1]])\n",
    "fil_rdd_2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('filamentA', '200W'), [2170, 4]),\n",
       " (('filamentB', '200W'), [2285, 4]),\n",
       " (('filamentB', '100W'), [2756, 4]),\n",
       " (('filamentA', '100W'), [2514, 4])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply reduceByKey\n",
    "fil_rdd_2_sum_count = fil_rdd_2.reduceByKey(lambda val1, val2: [val1[0]+val2[0], val1[1]+val2[1]])\n",
    "fil_rdd_2_sum_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('filamentA', '200W'), 542.5],\n",
       " [('filamentB', '200W'), 571.25],\n",
       " [('filamentB', '100W'), 689.0],\n",
       " [('filamentA', '100W'), 628.5]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean\n",
    "fil_rdd_2_mean = fil_rdd_2_sum_count.map(lambda val: [val[0], float(val[1][0]/val[1][1])])\n",
    "fil_rdd_2_mean.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Join Operations**\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Inner join**: Returns all the keys that are common to both the tables and discards uncommon keys.\n",
    "\n",
    "    - `join()`\n",
    "\n",
    "- **Left outer join**: Includes all keys in the left table and excludes uncommon keys from the right table.\n",
    "\n",
    "    - `leftOuterJoin()`\n",
    "\n",
    "- **Right outer join**: Every key of the second table is included where only common keys from first table are included\n",
    "\n",
    "    - `rightOuterJoin()`\n",
    "\n",
    "- **Full outer join**: Includes all the keys from both the tables\n",
    "\n",
    "    - `fullOuterJoin()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = [ \n",
    "    \"si1 Robin M\".split(),\n",
    "    \"si2 Maria F\".split(),\n",
    "    \"si3 Julie F\".split(),\n",
    "    \"si4 Bob M\".split(),\n",
    "    \"si6 William M\".split()\n",
    "]\n",
    "\n",
    "sub_data = [ \n",
    "    \"si1 Python\".split(),\n",
    "    \"si3 Java\".split(),\n",
    "    \"si1 Java\".split(),\n",
    "    \"si2 Python\".split(),\n",
    "    \"si3 Ruby\".split(),\n",
    "    \"si4 C++\".split(),\n",
    "    \"si5 C\".split(),\n",
    "    \"si4 Python\".split(),\n",
    "    \"si2 Java\".split()\n",
    "]\n",
    "\n",
    "student_rdd = spark.sparkContext.parallelize(student_data)\n",
    "subject_rdd = spark.sparkContext.parallelize(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['si1', 'Robin', 'M'], ['si2', 'Maria', 'F'], ['si3', 'Julie', 'F'], ['si4', 'Bob', 'M'], ['si6', 'William', 'M']]\n",
      "\n",
      "[['si1', 'Python'], ['si3', 'Java'], ['si1', 'Java'], ['si2', 'Python']]\n"
     ]
    }
   ],
   "source": [
    "print(student_rdd.collect())\n",
    "print()\n",
    "print(subject_rdd.take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('si1', ['Robin', 'M']),\n",
       " ('si2', ['Maria', 'F']),\n",
       " ('si3', ['Julie', 'F']),\n",
       " ('si4', ['Bob', 'M'])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform student rdd to paired rdd\n",
    "\n",
    "student_rdd_paired = student_rdd.map(lambda val: (val[0], [val[1], val[2]]))\n",
    "student_rdd_paired.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('si1', 'Python'), ('si3', 'Java'), ('si1', 'Java')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform subject rdd to paired rdd\n",
    "subject_rdd_paired = subject_rdd.map(lambda val: (val[0], val[1]))\n",
    "subject_rdd_paired.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['si4', 'si3', 'si5', 'si1', 'si2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(subject_rdd_paired.keys().distinct().collect()) # check keys of subject rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('si3', (['Julie', 'F'], 'Java')),\n",
       " ('si3', (['Julie', 'F'], 'Ruby')),\n",
       " ('si2', (['Maria', 'F'], 'Python')),\n",
       " ('si2', (['Maria', 'F'], 'Java')),\n",
       " ('si4', (['Bob', 'M'], 'C++')),\n",
       " ('si4', (['Bob', 'M'], 'Python')),\n",
       " ('si1', (['Robin', 'M'], 'Python')),\n",
       " ('si1', (['Robin', 'M'], 'Java'))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inner join\n",
    "\n",
    "stu_sub_inner_join = student_rdd_paired.join(subject_rdd_paired)\n",
    "stu_sub_inner_join.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('si3', (['Julie', 'F'], 'Java')),\n",
       " ('si3', (['Julie', 'F'], 'Ruby')),\n",
       " ('si2', (['Maria', 'F'], 'Python')),\n",
       " ('si2', (['Maria', 'F'], 'Java')),\n",
       " ('si4', (['Bob', 'M'], 'C++')),\n",
       " ('si4', (['Bob', 'M'], 'Python')),\n",
       " ('si6', (['William', 'M'], None)),\n",
       " ('si1', (['Robin', 'M'], 'Python')),\n",
       " ('si1', (['Robin', 'M'], 'Java'))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left outer join\n",
    "\n",
    "stu_sub_left_outer_join = student_rdd_paired.leftOuterJoin(subject_rdd_paired)\n",
    "stu_sub_left_outer_join.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('si3', (['Julie', 'F'], 'Java')),\n",
       " ('si3', (['Julie', 'F'], 'Ruby')),\n",
       " ('si5', (None, 'C')),\n",
       " ('si2', (['Maria', 'F'], 'Python')),\n",
       " ('si2', (['Maria', 'F'], 'Java')),\n",
       " ('si4', (['Bob', 'M'], 'C++')),\n",
       " ('si4', (['Bob', 'M'], 'Python')),\n",
       " ('si1', (['Robin', 'M'], 'Python')),\n",
       " ('si1', (['Robin', 'M'], 'Java'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# right outer join\n",
    "stu_sub_right_outer_join = student_rdd_paired.rightOuterJoin(subject_rdd_paired)\n",
    "stu_sub_right_outer_join.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('si3', (['Julie', 'F'], 'Java')),\n",
       " ('si3', (['Julie', 'F'], 'Ruby')),\n",
       " ('si5', (None, 'C')),\n",
       " ('si2', (['Maria', 'F'], 'Python')),\n",
       " ('si2', (['Maria', 'F'], 'Java')),\n",
       " ('si4', (['Bob', 'M'], 'C++')),\n",
       " ('si4', (['Bob', 'M'], 'Python')),\n",
       " ('si6', (['William', 'M'], None)),\n",
       " ('si1', (['Robin', 'M'], 'Python')),\n",
       " ('si1', (['Robin', 'M'], 'Java'))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full outer join\n",
    "\n",
    "stu_sub_full_outer_join = student_rdd_paired.fullOuterJoin(subject_rdd_paired)\n",
    "stu_sub_full_outer_join.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_ttl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec  7 2022, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e5fe3c56a0f8f95c221320b0bd7b50af4bf76cfb19c727317c7f47c8ed217d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
